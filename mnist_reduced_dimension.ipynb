{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd72c23",
   "metadata": {},
   "source": [
    "We work with the MNIST dataset.\n",
    "\n",
    "Here are the packages we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3283136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9592422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__ #version of scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4064093d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.5'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__ #version of numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0530e126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpl.__version__ #version of matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a136791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist = fetch_openml('mnist_784') \n",
    "mnist = fetch_openml('mnist_784', version = 1, as_frame = False) #this as_frame = False will deliver a numpy.ndarray\n",
    "#helps makes sense of X[0] in some_digit defintion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e13b64a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'target': array(['5', '0', '4', ..., '4', '5', '6'], dtype=object),\n",
       " 'frame': None,\n",
       " 'categories': {},\n",
       " 'feature_names': ['pixel1',\n",
       "  'pixel2',\n",
       "  'pixel3',\n",
       "  'pixel4',\n",
       "  'pixel5',\n",
       "  'pixel6',\n",
       "  'pixel7',\n",
       "  'pixel8',\n",
       "  'pixel9',\n",
       "  'pixel10',\n",
       "  'pixel11',\n",
       "  'pixel12',\n",
       "  'pixel13',\n",
       "  'pixel14',\n",
       "  'pixel15',\n",
       "  'pixel16',\n",
       "  'pixel17',\n",
       "  'pixel18',\n",
       "  'pixel19',\n",
       "  'pixel20',\n",
       "  'pixel21',\n",
       "  'pixel22',\n",
       "  'pixel23',\n",
       "  'pixel24',\n",
       "  'pixel25',\n",
       "  'pixel26',\n",
       "  'pixel27',\n",
       "  'pixel28',\n",
       "  'pixel29',\n",
       "  'pixel30',\n",
       "  'pixel31',\n",
       "  'pixel32',\n",
       "  'pixel33',\n",
       "  'pixel34',\n",
       "  'pixel35',\n",
       "  'pixel36',\n",
       "  'pixel37',\n",
       "  'pixel38',\n",
       "  'pixel39',\n",
       "  'pixel40',\n",
       "  'pixel41',\n",
       "  'pixel42',\n",
       "  'pixel43',\n",
       "  'pixel44',\n",
       "  'pixel45',\n",
       "  'pixel46',\n",
       "  'pixel47',\n",
       "  'pixel48',\n",
       "  'pixel49',\n",
       "  'pixel50',\n",
       "  'pixel51',\n",
       "  'pixel52',\n",
       "  'pixel53',\n",
       "  'pixel54',\n",
       "  'pixel55',\n",
       "  'pixel56',\n",
       "  'pixel57',\n",
       "  'pixel58',\n",
       "  'pixel59',\n",
       "  'pixel60',\n",
       "  'pixel61',\n",
       "  'pixel62',\n",
       "  'pixel63',\n",
       "  'pixel64',\n",
       "  'pixel65',\n",
       "  'pixel66',\n",
       "  'pixel67',\n",
       "  'pixel68',\n",
       "  'pixel69',\n",
       "  'pixel70',\n",
       "  'pixel71',\n",
       "  'pixel72',\n",
       "  'pixel73',\n",
       "  'pixel74',\n",
       "  'pixel75',\n",
       "  'pixel76',\n",
       "  'pixel77',\n",
       "  'pixel78',\n",
       "  'pixel79',\n",
       "  'pixel80',\n",
       "  'pixel81',\n",
       "  'pixel82',\n",
       "  'pixel83',\n",
       "  'pixel84',\n",
       "  'pixel85',\n",
       "  'pixel86',\n",
       "  'pixel87',\n",
       "  'pixel88',\n",
       "  'pixel89',\n",
       "  'pixel90',\n",
       "  'pixel91',\n",
       "  'pixel92',\n",
       "  'pixel93',\n",
       "  'pixel94',\n",
       "  'pixel95',\n",
       "  'pixel96',\n",
       "  'pixel97',\n",
       "  'pixel98',\n",
       "  'pixel99',\n",
       "  'pixel100',\n",
       "  'pixel101',\n",
       "  'pixel102',\n",
       "  'pixel103',\n",
       "  'pixel104',\n",
       "  'pixel105',\n",
       "  'pixel106',\n",
       "  'pixel107',\n",
       "  'pixel108',\n",
       "  'pixel109',\n",
       "  'pixel110',\n",
       "  'pixel111',\n",
       "  'pixel112',\n",
       "  'pixel113',\n",
       "  'pixel114',\n",
       "  'pixel115',\n",
       "  'pixel116',\n",
       "  'pixel117',\n",
       "  'pixel118',\n",
       "  'pixel119',\n",
       "  'pixel120',\n",
       "  'pixel121',\n",
       "  'pixel122',\n",
       "  'pixel123',\n",
       "  'pixel124',\n",
       "  'pixel125',\n",
       "  'pixel126',\n",
       "  'pixel127',\n",
       "  'pixel128',\n",
       "  'pixel129',\n",
       "  'pixel130',\n",
       "  'pixel131',\n",
       "  'pixel132',\n",
       "  'pixel133',\n",
       "  'pixel134',\n",
       "  'pixel135',\n",
       "  'pixel136',\n",
       "  'pixel137',\n",
       "  'pixel138',\n",
       "  'pixel139',\n",
       "  'pixel140',\n",
       "  'pixel141',\n",
       "  'pixel142',\n",
       "  'pixel143',\n",
       "  'pixel144',\n",
       "  'pixel145',\n",
       "  'pixel146',\n",
       "  'pixel147',\n",
       "  'pixel148',\n",
       "  'pixel149',\n",
       "  'pixel150',\n",
       "  'pixel151',\n",
       "  'pixel152',\n",
       "  'pixel153',\n",
       "  'pixel154',\n",
       "  'pixel155',\n",
       "  'pixel156',\n",
       "  'pixel157',\n",
       "  'pixel158',\n",
       "  'pixel159',\n",
       "  'pixel160',\n",
       "  'pixel161',\n",
       "  'pixel162',\n",
       "  'pixel163',\n",
       "  'pixel164',\n",
       "  'pixel165',\n",
       "  'pixel166',\n",
       "  'pixel167',\n",
       "  'pixel168',\n",
       "  'pixel169',\n",
       "  'pixel170',\n",
       "  'pixel171',\n",
       "  'pixel172',\n",
       "  'pixel173',\n",
       "  'pixel174',\n",
       "  'pixel175',\n",
       "  'pixel176',\n",
       "  'pixel177',\n",
       "  'pixel178',\n",
       "  'pixel179',\n",
       "  'pixel180',\n",
       "  'pixel181',\n",
       "  'pixel182',\n",
       "  'pixel183',\n",
       "  'pixel184',\n",
       "  'pixel185',\n",
       "  'pixel186',\n",
       "  'pixel187',\n",
       "  'pixel188',\n",
       "  'pixel189',\n",
       "  'pixel190',\n",
       "  'pixel191',\n",
       "  'pixel192',\n",
       "  'pixel193',\n",
       "  'pixel194',\n",
       "  'pixel195',\n",
       "  'pixel196',\n",
       "  'pixel197',\n",
       "  'pixel198',\n",
       "  'pixel199',\n",
       "  'pixel200',\n",
       "  'pixel201',\n",
       "  'pixel202',\n",
       "  'pixel203',\n",
       "  'pixel204',\n",
       "  'pixel205',\n",
       "  'pixel206',\n",
       "  'pixel207',\n",
       "  'pixel208',\n",
       "  'pixel209',\n",
       "  'pixel210',\n",
       "  'pixel211',\n",
       "  'pixel212',\n",
       "  'pixel213',\n",
       "  'pixel214',\n",
       "  'pixel215',\n",
       "  'pixel216',\n",
       "  'pixel217',\n",
       "  'pixel218',\n",
       "  'pixel219',\n",
       "  'pixel220',\n",
       "  'pixel221',\n",
       "  'pixel222',\n",
       "  'pixel223',\n",
       "  'pixel224',\n",
       "  'pixel225',\n",
       "  'pixel226',\n",
       "  'pixel227',\n",
       "  'pixel228',\n",
       "  'pixel229',\n",
       "  'pixel230',\n",
       "  'pixel231',\n",
       "  'pixel232',\n",
       "  'pixel233',\n",
       "  'pixel234',\n",
       "  'pixel235',\n",
       "  'pixel236',\n",
       "  'pixel237',\n",
       "  'pixel238',\n",
       "  'pixel239',\n",
       "  'pixel240',\n",
       "  'pixel241',\n",
       "  'pixel242',\n",
       "  'pixel243',\n",
       "  'pixel244',\n",
       "  'pixel245',\n",
       "  'pixel246',\n",
       "  'pixel247',\n",
       "  'pixel248',\n",
       "  'pixel249',\n",
       "  'pixel250',\n",
       "  'pixel251',\n",
       "  'pixel252',\n",
       "  'pixel253',\n",
       "  'pixel254',\n",
       "  'pixel255',\n",
       "  'pixel256',\n",
       "  'pixel257',\n",
       "  'pixel258',\n",
       "  'pixel259',\n",
       "  'pixel260',\n",
       "  'pixel261',\n",
       "  'pixel262',\n",
       "  'pixel263',\n",
       "  'pixel264',\n",
       "  'pixel265',\n",
       "  'pixel266',\n",
       "  'pixel267',\n",
       "  'pixel268',\n",
       "  'pixel269',\n",
       "  'pixel270',\n",
       "  'pixel271',\n",
       "  'pixel272',\n",
       "  'pixel273',\n",
       "  'pixel274',\n",
       "  'pixel275',\n",
       "  'pixel276',\n",
       "  'pixel277',\n",
       "  'pixel278',\n",
       "  'pixel279',\n",
       "  'pixel280',\n",
       "  'pixel281',\n",
       "  'pixel282',\n",
       "  'pixel283',\n",
       "  'pixel284',\n",
       "  'pixel285',\n",
       "  'pixel286',\n",
       "  'pixel287',\n",
       "  'pixel288',\n",
       "  'pixel289',\n",
       "  'pixel290',\n",
       "  'pixel291',\n",
       "  'pixel292',\n",
       "  'pixel293',\n",
       "  'pixel294',\n",
       "  'pixel295',\n",
       "  'pixel296',\n",
       "  'pixel297',\n",
       "  'pixel298',\n",
       "  'pixel299',\n",
       "  'pixel300',\n",
       "  'pixel301',\n",
       "  'pixel302',\n",
       "  'pixel303',\n",
       "  'pixel304',\n",
       "  'pixel305',\n",
       "  'pixel306',\n",
       "  'pixel307',\n",
       "  'pixel308',\n",
       "  'pixel309',\n",
       "  'pixel310',\n",
       "  'pixel311',\n",
       "  'pixel312',\n",
       "  'pixel313',\n",
       "  'pixel314',\n",
       "  'pixel315',\n",
       "  'pixel316',\n",
       "  'pixel317',\n",
       "  'pixel318',\n",
       "  'pixel319',\n",
       "  'pixel320',\n",
       "  'pixel321',\n",
       "  'pixel322',\n",
       "  'pixel323',\n",
       "  'pixel324',\n",
       "  'pixel325',\n",
       "  'pixel326',\n",
       "  'pixel327',\n",
       "  'pixel328',\n",
       "  'pixel329',\n",
       "  'pixel330',\n",
       "  'pixel331',\n",
       "  'pixel332',\n",
       "  'pixel333',\n",
       "  'pixel334',\n",
       "  'pixel335',\n",
       "  'pixel336',\n",
       "  'pixel337',\n",
       "  'pixel338',\n",
       "  'pixel339',\n",
       "  'pixel340',\n",
       "  'pixel341',\n",
       "  'pixel342',\n",
       "  'pixel343',\n",
       "  'pixel344',\n",
       "  'pixel345',\n",
       "  'pixel346',\n",
       "  'pixel347',\n",
       "  'pixel348',\n",
       "  'pixel349',\n",
       "  'pixel350',\n",
       "  'pixel351',\n",
       "  'pixel352',\n",
       "  'pixel353',\n",
       "  'pixel354',\n",
       "  'pixel355',\n",
       "  'pixel356',\n",
       "  'pixel357',\n",
       "  'pixel358',\n",
       "  'pixel359',\n",
       "  'pixel360',\n",
       "  'pixel361',\n",
       "  'pixel362',\n",
       "  'pixel363',\n",
       "  'pixel364',\n",
       "  'pixel365',\n",
       "  'pixel366',\n",
       "  'pixel367',\n",
       "  'pixel368',\n",
       "  'pixel369',\n",
       "  'pixel370',\n",
       "  'pixel371',\n",
       "  'pixel372',\n",
       "  'pixel373',\n",
       "  'pixel374',\n",
       "  'pixel375',\n",
       "  'pixel376',\n",
       "  'pixel377',\n",
       "  'pixel378',\n",
       "  'pixel379',\n",
       "  'pixel380',\n",
       "  'pixel381',\n",
       "  'pixel382',\n",
       "  'pixel383',\n",
       "  'pixel384',\n",
       "  'pixel385',\n",
       "  'pixel386',\n",
       "  'pixel387',\n",
       "  'pixel388',\n",
       "  'pixel389',\n",
       "  'pixel390',\n",
       "  'pixel391',\n",
       "  'pixel392',\n",
       "  'pixel393',\n",
       "  'pixel394',\n",
       "  'pixel395',\n",
       "  'pixel396',\n",
       "  'pixel397',\n",
       "  'pixel398',\n",
       "  'pixel399',\n",
       "  'pixel400',\n",
       "  'pixel401',\n",
       "  'pixel402',\n",
       "  'pixel403',\n",
       "  'pixel404',\n",
       "  'pixel405',\n",
       "  'pixel406',\n",
       "  'pixel407',\n",
       "  'pixel408',\n",
       "  'pixel409',\n",
       "  'pixel410',\n",
       "  'pixel411',\n",
       "  'pixel412',\n",
       "  'pixel413',\n",
       "  'pixel414',\n",
       "  'pixel415',\n",
       "  'pixel416',\n",
       "  'pixel417',\n",
       "  'pixel418',\n",
       "  'pixel419',\n",
       "  'pixel420',\n",
       "  'pixel421',\n",
       "  'pixel422',\n",
       "  'pixel423',\n",
       "  'pixel424',\n",
       "  'pixel425',\n",
       "  'pixel426',\n",
       "  'pixel427',\n",
       "  'pixel428',\n",
       "  'pixel429',\n",
       "  'pixel430',\n",
       "  'pixel431',\n",
       "  'pixel432',\n",
       "  'pixel433',\n",
       "  'pixel434',\n",
       "  'pixel435',\n",
       "  'pixel436',\n",
       "  'pixel437',\n",
       "  'pixel438',\n",
       "  'pixel439',\n",
       "  'pixel440',\n",
       "  'pixel441',\n",
       "  'pixel442',\n",
       "  'pixel443',\n",
       "  'pixel444',\n",
       "  'pixel445',\n",
       "  'pixel446',\n",
       "  'pixel447',\n",
       "  'pixel448',\n",
       "  'pixel449',\n",
       "  'pixel450',\n",
       "  'pixel451',\n",
       "  'pixel452',\n",
       "  'pixel453',\n",
       "  'pixel454',\n",
       "  'pixel455',\n",
       "  'pixel456',\n",
       "  'pixel457',\n",
       "  'pixel458',\n",
       "  'pixel459',\n",
       "  'pixel460',\n",
       "  'pixel461',\n",
       "  'pixel462',\n",
       "  'pixel463',\n",
       "  'pixel464',\n",
       "  'pixel465',\n",
       "  'pixel466',\n",
       "  'pixel467',\n",
       "  'pixel468',\n",
       "  'pixel469',\n",
       "  'pixel470',\n",
       "  'pixel471',\n",
       "  'pixel472',\n",
       "  'pixel473',\n",
       "  'pixel474',\n",
       "  'pixel475',\n",
       "  'pixel476',\n",
       "  'pixel477',\n",
       "  'pixel478',\n",
       "  'pixel479',\n",
       "  'pixel480',\n",
       "  'pixel481',\n",
       "  'pixel482',\n",
       "  'pixel483',\n",
       "  'pixel484',\n",
       "  'pixel485',\n",
       "  'pixel486',\n",
       "  'pixel487',\n",
       "  'pixel488',\n",
       "  'pixel489',\n",
       "  'pixel490',\n",
       "  'pixel491',\n",
       "  'pixel492',\n",
       "  'pixel493',\n",
       "  'pixel494',\n",
       "  'pixel495',\n",
       "  'pixel496',\n",
       "  'pixel497',\n",
       "  'pixel498',\n",
       "  'pixel499',\n",
       "  'pixel500',\n",
       "  'pixel501',\n",
       "  'pixel502',\n",
       "  'pixel503',\n",
       "  'pixel504',\n",
       "  'pixel505',\n",
       "  'pixel506',\n",
       "  'pixel507',\n",
       "  'pixel508',\n",
       "  'pixel509',\n",
       "  'pixel510',\n",
       "  'pixel511',\n",
       "  'pixel512',\n",
       "  'pixel513',\n",
       "  'pixel514',\n",
       "  'pixel515',\n",
       "  'pixel516',\n",
       "  'pixel517',\n",
       "  'pixel518',\n",
       "  'pixel519',\n",
       "  'pixel520',\n",
       "  'pixel521',\n",
       "  'pixel522',\n",
       "  'pixel523',\n",
       "  'pixel524',\n",
       "  'pixel525',\n",
       "  'pixel526',\n",
       "  'pixel527',\n",
       "  'pixel528',\n",
       "  'pixel529',\n",
       "  'pixel530',\n",
       "  'pixel531',\n",
       "  'pixel532',\n",
       "  'pixel533',\n",
       "  'pixel534',\n",
       "  'pixel535',\n",
       "  'pixel536',\n",
       "  'pixel537',\n",
       "  'pixel538',\n",
       "  'pixel539',\n",
       "  'pixel540',\n",
       "  'pixel541',\n",
       "  'pixel542',\n",
       "  'pixel543',\n",
       "  'pixel544',\n",
       "  'pixel545',\n",
       "  'pixel546',\n",
       "  'pixel547',\n",
       "  'pixel548',\n",
       "  'pixel549',\n",
       "  'pixel550',\n",
       "  'pixel551',\n",
       "  'pixel552',\n",
       "  'pixel553',\n",
       "  'pixel554',\n",
       "  'pixel555',\n",
       "  'pixel556',\n",
       "  'pixel557',\n",
       "  'pixel558',\n",
       "  'pixel559',\n",
       "  'pixel560',\n",
       "  'pixel561',\n",
       "  'pixel562',\n",
       "  'pixel563',\n",
       "  'pixel564',\n",
       "  'pixel565',\n",
       "  'pixel566',\n",
       "  'pixel567',\n",
       "  'pixel568',\n",
       "  'pixel569',\n",
       "  'pixel570',\n",
       "  'pixel571',\n",
       "  'pixel572',\n",
       "  'pixel573',\n",
       "  'pixel574',\n",
       "  'pixel575',\n",
       "  'pixel576',\n",
       "  'pixel577',\n",
       "  'pixel578',\n",
       "  'pixel579',\n",
       "  'pixel580',\n",
       "  'pixel581',\n",
       "  'pixel582',\n",
       "  'pixel583',\n",
       "  'pixel584',\n",
       "  'pixel585',\n",
       "  'pixel586',\n",
       "  'pixel587',\n",
       "  'pixel588',\n",
       "  'pixel589',\n",
       "  'pixel590',\n",
       "  'pixel591',\n",
       "  'pixel592',\n",
       "  'pixel593',\n",
       "  'pixel594',\n",
       "  'pixel595',\n",
       "  'pixel596',\n",
       "  'pixel597',\n",
       "  'pixel598',\n",
       "  'pixel599',\n",
       "  'pixel600',\n",
       "  'pixel601',\n",
       "  'pixel602',\n",
       "  'pixel603',\n",
       "  'pixel604',\n",
       "  'pixel605',\n",
       "  'pixel606',\n",
       "  'pixel607',\n",
       "  'pixel608',\n",
       "  'pixel609',\n",
       "  'pixel610',\n",
       "  'pixel611',\n",
       "  'pixel612',\n",
       "  'pixel613',\n",
       "  'pixel614',\n",
       "  'pixel615',\n",
       "  'pixel616',\n",
       "  'pixel617',\n",
       "  'pixel618',\n",
       "  'pixel619',\n",
       "  'pixel620',\n",
       "  'pixel621',\n",
       "  'pixel622',\n",
       "  'pixel623',\n",
       "  'pixel624',\n",
       "  'pixel625',\n",
       "  'pixel626',\n",
       "  'pixel627',\n",
       "  'pixel628',\n",
       "  'pixel629',\n",
       "  'pixel630',\n",
       "  'pixel631',\n",
       "  'pixel632',\n",
       "  'pixel633',\n",
       "  'pixel634',\n",
       "  'pixel635',\n",
       "  'pixel636',\n",
       "  'pixel637',\n",
       "  'pixel638',\n",
       "  'pixel639',\n",
       "  'pixel640',\n",
       "  'pixel641',\n",
       "  'pixel642',\n",
       "  'pixel643',\n",
       "  'pixel644',\n",
       "  'pixel645',\n",
       "  'pixel646',\n",
       "  'pixel647',\n",
       "  'pixel648',\n",
       "  'pixel649',\n",
       "  'pixel650',\n",
       "  'pixel651',\n",
       "  'pixel652',\n",
       "  'pixel653',\n",
       "  'pixel654',\n",
       "  'pixel655',\n",
       "  'pixel656',\n",
       "  'pixel657',\n",
       "  'pixel658',\n",
       "  'pixel659',\n",
       "  'pixel660',\n",
       "  'pixel661',\n",
       "  'pixel662',\n",
       "  'pixel663',\n",
       "  'pixel664',\n",
       "  'pixel665',\n",
       "  'pixel666',\n",
       "  'pixel667',\n",
       "  'pixel668',\n",
       "  'pixel669',\n",
       "  'pixel670',\n",
       "  'pixel671',\n",
       "  'pixel672',\n",
       "  'pixel673',\n",
       "  'pixel674',\n",
       "  'pixel675',\n",
       "  'pixel676',\n",
       "  'pixel677',\n",
       "  'pixel678',\n",
       "  'pixel679',\n",
       "  'pixel680',\n",
       "  'pixel681',\n",
       "  'pixel682',\n",
       "  'pixel683',\n",
       "  'pixel684',\n",
       "  'pixel685',\n",
       "  'pixel686',\n",
       "  'pixel687',\n",
       "  'pixel688',\n",
       "  'pixel689',\n",
       "  'pixel690',\n",
       "  'pixel691',\n",
       "  'pixel692',\n",
       "  'pixel693',\n",
       "  'pixel694',\n",
       "  'pixel695',\n",
       "  'pixel696',\n",
       "  'pixel697',\n",
       "  'pixel698',\n",
       "  'pixel699',\n",
       "  'pixel700',\n",
       "  'pixel701',\n",
       "  'pixel702',\n",
       "  'pixel703',\n",
       "  'pixel704',\n",
       "  'pixel705',\n",
       "  'pixel706',\n",
       "  'pixel707',\n",
       "  'pixel708',\n",
       "  'pixel709',\n",
       "  'pixel710',\n",
       "  'pixel711',\n",
       "  'pixel712',\n",
       "  'pixel713',\n",
       "  'pixel714',\n",
       "  'pixel715',\n",
       "  'pixel716',\n",
       "  'pixel717',\n",
       "  'pixel718',\n",
       "  'pixel719',\n",
       "  'pixel720',\n",
       "  'pixel721',\n",
       "  'pixel722',\n",
       "  'pixel723',\n",
       "  'pixel724',\n",
       "  'pixel725',\n",
       "  'pixel726',\n",
       "  'pixel727',\n",
       "  'pixel728',\n",
       "  'pixel729',\n",
       "  'pixel730',\n",
       "  'pixel731',\n",
       "  'pixel732',\n",
       "  'pixel733',\n",
       "  'pixel734',\n",
       "  'pixel735',\n",
       "  'pixel736',\n",
       "  'pixel737',\n",
       "  'pixel738',\n",
       "  'pixel739',\n",
       "  'pixel740',\n",
       "  'pixel741',\n",
       "  'pixel742',\n",
       "  'pixel743',\n",
       "  'pixel744',\n",
       "  'pixel745',\n",
       "  'pixel746',\n",
       "  'pixel747',\n",
       "  'pixel748',\n",
       "  'pixel749',\n",
       "  'pixel750',\n",
       "  'pixel751',\n",
       "  'pixel752',\n",
       "  'pixel753',\n",
       "  'pixel754',\n",
       "  'pixel755',\n",
       "  'pixel756',\n",
       "  'pixel757',\n",
       "  'pixel758',\n",
       "  'pixel759',\n",
       "  'pixel760',\n",
       "  'pixel761',\n",
       "  'pixel762',\n",
       "  'pixel763',\n",
       "  'pixel764',\n",
       "  'pixel765',\n",
       "  'pixel766',\n",
       "  'pixel767',\n",
       "  'pixel768',\n",
       "  'pixel769',\n",
       "  'pixel770',\n",
       "  'pixel771',\n",
       "  'pixel772',\n",
       "  'pixel773',\n",
       "  'pixel774',\n",
       "  'pixel775',\n",
       "  'pixel776',\n",
       "  'pixel777',\n",
       "  'pixel778',\n",
       "  'pixel779',\n",
       "  'pixel780',\n",
       "  'pixel781',\n",
       "  'pixel782',\n",
       "  'pixel783',\n",
       "  'pixel784'],\n",
       " 'target_names': ['class'],\n",
       " 'DESCR': \"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \\n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \\n**Please cite**:  \\n\\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \\n\\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \\n\\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \\n\\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\\n\\nDownloaded from openml.org.\",\n",
       " 'details': {'id': '554',\n",
       "  'name': 'mnist_784',\n",
       "  'version': '1',\n",
       "  'description_version': '1',\n",
       "  'format': 'ARFF',\n",
       "  'creator': ['Yann LeCun', 'Corinna Cortes', 'Christopher J.C. Burges'],\n",
       "  'upload_date': '2014-09-29T03:28:38',\n",
       "  'language': 'English',\n",
       "  'licence': 'Public',\n",
       "  'url': 'https://old.openml.org/data/v1/download/52667/mnist_784.arff',\n",
       "  'file_id': '52667',\n",
       "  'default_target_attribute': 'class',\n",
       "  'tag': ['AzurePilot',\n",
       "   'OpenML-CC18',\n",
       "   'OpenML100',\n",
       "   'study_1',\n",
       "   'study_123',\n",
       "   'study_41',\n",
       "   'study_99',\n",
       "   'vision'],\n",
       "  'visibility': 'public',\n",
       "  'minio_url': 'http://openml1.win.tue.nl/dataset554/dataset_554.pq',\n",
       "  'status': 'active',\n",
       "  'processing_date': '2020-11-20 20:12:09',\n",
       "  'md5_checksum': '0298d579eb1b86163de7723944c7e495'},\n",
       " 'url': 'https://www.openml.org/d/554'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5a246c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb034791",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49fa99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e8c9b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1c3393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap= \"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3343bd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03218090",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8) #converts y[i]'s to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5139a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the MNIST dataset into 60000 training images and 10000 for testing. Normally, we would leave it there. \n",
    "But instead we do PCA.\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d59be",
   "metadata": {},
   "source": [
    "We now conduct dimensionality reduction by principal component analysis (PCA). This reduces the time to run the\n",
    "OneVsRestClassifier/OneVsOneClassifier and even the SGD Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33e8c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.95)\n",
    "X_pca = pca.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f8a9915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 154)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape #This only has 154 y-coordinates as opposed to 784"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad5f0e",
   "metadata": {},
   "source": [
    "Let us see what dimensionality reduction has done to X[0] (we identified it earlier as 5). We use inverse_transform. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8dad434",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inv_pca = pca.inverse_transform(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff618d",
   "metadata": {},
   "source": [
    "The X_inv_pca[0] is still 5 and dimensionality reduction has not affected it, as we see next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d52e7c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "same_digit = X_inv_pca[0]\n",
    "same_digit_image = same_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(same_digit_image, cmap= \"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff837b",
   "metadata": {},
   "source": [
    "However, to make sure that PCA reduction has not distorted our image of 5 in X[0] significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0c611",
   "metadata": {},
   "source": [
    "First we employ a support a support vector machine in conjunction with Principal Component Analysis dimensionality reduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6938587",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm =  SVC()\n",
    "t_0 = time.time()\n",
    "svm.fit(X_pca, y_train)\n",
    "t_1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36974e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.3106517791748\n"
     ]
    }
   ],
   "source": [
    "svm_training_time = t_1- t_0\n",
    "print(svm_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c13653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict([X_pca[0]]) #does correctly identify it as 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "406375b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98045, 0.97745, 0.97885])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm, X_pca, y_train, cv= 3, scoring = \"accuracy\") #it shows accuracy of roughly 98%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53f0d9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "y_svm_pca = cross_val_predict(svm, X_pca, y_train, cv = 3)\n",
    "print(y_svm_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0888be36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9789094200451905\n"
     ]
    }
   ],
   "source": [
    "svm_pca_precision = precision_score(y_train, y_svm_pca, average='weighted')\n",
    "print(svm_pca_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f056978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9789166666666667\n"
     ]
    }
   ],
   "source": [
    "svm_pca_recall = recall_score(y_train, y_svm_pca, average='weighted')\n",
    "print(svm_pca_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185923ed",
   "metadata": {},
   "source": [
    "We employ the OneVsRestClassifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97fbfddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr = OneVsRestClassifier(SVC())\n",
    "t_3= time.time()\n",
    "ovr.fit(X_pca, y_train)\n",
    "t_4 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2e260da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597.441125869751\n"
     ]
    }
   ],
   "source": [
    "ovr_training_time = t_4-t_3\n",
    "print(ovr_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb65aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98185 0.97865 0.9787 ]\n"
     ]
    }
   ],
   "source": [
    "t_5 =time.time()\n",
    "print(cross_val_score(ovr, X_pca, y_train, cv=3, scoring = \"accuracy\"))\n",
    "t_6 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c841c558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866.3223266601562\n"
     ]
    }
   ],
   "source": [
    "cross_val_ovr_training_time = t_6-t_5\n",
    "print(cross_val_ovr_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46f834c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "y_ovr_pca = cross_val_predict(ovr, X_pca, y_train, cv = 3)\n",
    "print(y_ovr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6bbcd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797318869328284\n"
     ]
    }
   ],
   "source": [
    "ovr_pca_precision = precision_score(y_train, y_ovr_pca, average='weighted')\n",
    "print(ovr_pca_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1bcdeec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797333333333333\n"
     ]
    }
   ],
   "source": [
    "ovr_pca_recall = recall_score(y_train, y_ovr_pca, average='weighted')\n",
    "print(ovr_pca_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3701b9",
   "metadata": {},
   "source": [
    "The OneVsRestClassifier takes 648 seconds to train! We this resort to Incremental PCA, where we divide the MNIST dataset into \n",
    "100 batches and use incremental PCA to reduce the dimension to 154 as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "654cc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 100\n",
    "ipca = IncrementalPCA(n_components = 154)\n",
    "t_7 = time.time()\n",
    "for train_batch in np.array_split(X_train, n_batches):\n",
    "    ipca.partial_fit(train_batch)\n",
    "    \n",
    "X_ipca = ipca.transform(X_train)\n",
    "t_8 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cddf8a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.91735029220581\n"
     ]
    }
   ],
   "source": [
    "incremental_pca_training_time = t_8 - t_7\n",
    "print(incremental_pca_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd0563b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_ipca = OneVsRestClassifier(SVC())\n",
    "\n",
    "t_9= time.time()\n",
    "ovr_ipca.fit(X_ipca, y_train)\n",
    "t_10 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c20bee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577.2291584014893\n"
     ]
    }
   ],
   "source": [
    "ovr_ipca_training_time = t_10-t_9\n",
    "print(t_10-t_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "622864be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98195 0.97855 0.97885]\n"
     ]
    }
   ],
   "source": [
    "t_11 = time.time()\n",
    "print(cross_val_score(ovr_ipca, X_ipca, y_train, cv = 3, scoring = \"accuracy\"))\n",
    "t_12 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4958cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920.5151655673981\n"
     ]
    }
   ],
   "source": [
    "print(t_12-t_11) #cross validation time required for ovr_ipca is about 1058 seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51f8a73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 154)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ipca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35a1ce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "y_ovr_ipca = cross_val_predict(ovr, X_ipca, y_train, cv = 3)\n",
    "print(y_ovr_ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e9c8e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797836519174132\n"
     ]
    }
   ],
   "source": [
    "ovr_ipca_precision = precision_score(y_train, y_ovr_ipca, average='weighted')\n",
    "print(ovr_ipca_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "752da74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797833333333333\n"
     ]
    }
   ],
   "source": [
    "ovr_ipca_recall = recall_score(y_train, y_ovr_ipca, average='weighted')\n",
    "print(ovr_ipca_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde47518",
   "metadata": {},
   "source": [
    "Let's give the Stochastic Gradient Descent a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "989774b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_13 = time.time()\n",
    "sgd = SGDClassifier(random_state = 2)\n",
    "sgd.fit(X_ipca, y_train)\n",
    "t_14 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "439c0362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.821831464767456\n"
     ]
    }
   ],
   "source": [
    "sgd_time = t_14-t_13\n",
    "print(sgd_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffe498d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88265 0.8813  0.89215]\n"
     ]
    }
   ],
   "source": [
    "t_15 = time.time()\n",
    "print(cross_val_score(sgd, X_ipca, y_train, cv = 3, scoring = \"accuracy\"))\n",
    "t_16 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "274ee9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.45901226997375\n"
     ]
    }
   ],
   "source": [
    "cross_validation_time_sgd = t_16-t_15\n",
    "print(cross_validation_time_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6d03883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "y_sgd_ipca = cross_val_predict(sgd, X_ipca, y_train, cv = 3)\n",
    "print(y_ovr_ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4f55552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797836519174132\n"
     ]
    }
   ],
   "source": [
    "sgd_ipca_precision = precision_score(y_train, y_sgd_ipca, average='weighted')\n",
    "print(ovr_ipca_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3eec2f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797833333333333\n"
     ]
    }
   ],
   "source": [
    "sgd_ipca_recall = recall_score(y_train, y_sgd_ipca, average='weighted')\n",
    "print(ovr_ipca_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a810dad",
   "metadata": {},
   "source": [
    "Just for the sake of completeness, let us now use the svm on X_ipac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c940e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ipca =  SVC()\n",
    "t_17 = time.time()\n",
    "svm_ipca.fit(X_ipca, y_train)\n",
    "t_18 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23c374f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.9256136417389\n"
     ]
    }
   ],
   "source": [
    "svm_ipca_train_time = t_18-t_17\n",
    "print(svm_ipca_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "252a279c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98045 0.9777  0.9791 ]\n"
     ]
    }
   ],
   "source": [
    "t_19 = time.time()\n",
    "print(cross_val_score(svm_ipca, X_ipca, y_train, cv = 3, scoring = \"accuracy\"))\n",
    "t_20 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3b9f452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364.21145510673523"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_20-t_19 #time for cross validation cvm_ipca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2cdcc94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "y_svm_ipca = cross_val_predict(svm, X_ipca, y_train, cv = 3)\n",
    "print(y_svm_ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "757c8332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9790752567433006\n"
     ]
    }
   ],
   "source": [
    "svm_ipca_precision = precision_score(y_train, y_svm_ipca, average='weighted')\n",
    "print(svm_ipca_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f5e8790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9790833333333333\n"
     ]
    }
   ],
   "source": [
    "svm_ipca_recall = recall_score(y_train, y_svm_ipca, average='weighted')\n",
    "print(svm_ipca_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55e359",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a72c5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "t_21 = time.time()\n",
    "rf.fit(X_ipca, y_train)\n",
    "t_22 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54df7645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.94769597053528\n"
     ]
    }
   ],
   "source": [
    "rf_train_time = t_22-t_21\n",
    "print(rf_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28af767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94375 0.9372  0.94305]\n"
     ]
    }
   ],
   "source": [
    "t_23 = time.time()\n",
    "print(cross_val_score(rf, X_ipca, y_train, cv= 3, scoring = \"accuracy\"))\n",
    "t_24= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f61658a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230.5682201385498"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_24-t_23 #cross validation time for random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52495602",
   "metadata": {},
   "source": [
    "Let's just work with the Random Forest Classifier with just the X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8a973d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators = 100)\n",
    "t_25 = time.time()\n",
    "rf2.fit(X_pca, y_train)\n",
    "t_26=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e83a0cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.46941542625427\n"
     ]
    }
   ],
   "source": [
    "rf2_train_time = t_26-t_25\n",
    "print(rf2_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "887267af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9425 0.9381 0.9436]\n"
     ]
    }
   ],
   "source": [
    "t_27 = time.time()\n",
    "print(cross_val_score(rf, X_pca, y_train, cv= 3, scoring = \"accuracy\"))\n",
    "t_28= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93e658f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.1738612651825"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_28-t_27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a3702",
   "metadata": {},
   "source": [
    "And finally, just to satisfy our curiosity, we run a random forest classifier naively on X_train without dimensionality\n",
    "reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d290d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(n_estimators = 100)\n",
    "t_29 = time.time()\n",
    "rf3.fit(X_train, y_train)\n",
    "t_30 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "826de11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.05427622795105\n"
     ]
    }
   ],
   "source": [
    "rf3_train_time = t_30-t_29\n",
    "print(rf3_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1aef5479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9647 0.9633 0.9668]\n"
     ]
    }
   ],
   "source": [
    "t_31 = time.time()\n",
    "print(cross_val_score(rf3, X_train, y_train, cv= 3, scoring = \"accuracy\"))\n",
    "t_32= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe523e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.65859413146973"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_32-t_31 #cross validation time for random forest without pca reduction on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79c17459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "y_rf3 = cross_val_predict(rf3, X_train, y_train, cv=3)\n",
    "print(y_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cfbf06bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9652275266912358\n"
     ]
    }
   ],
   "source": [
    "rf3_precision = precision_score(y_train, y_rf3, average='weighted')\n",
    "print(rf3_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36243ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96525\n"
     ]
    }
   ],
   "source": [
    "rf3_recall = recall_score(y_train, y_rf3, average='weighted')\n",
    "print(rf3_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104bd1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e21c85d",
   "metadata": {},
   "source": [
    "We begin by dimensionality reduction on the X_test using PCA. This will help us in testing our different models.\n",
    "The three candidates based on training time and accuracy are SVM (trained over X_pca), random forest classifier trained over X_test and the OneVsRestClassifier trained over X_pca. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "caadf05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components = 154)\n",
    "X_pca_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16c4378c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 154)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb5308e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = svm.predict(X_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34077023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of incorrect predictions is 168\n"
     ]
    }
   ],
   "source": [
    "incorrect_predictions = (y_test != y_predicted).sum()\n",
    "\n",
    "print('The number of incorrect predictions is %d' %(y_test != y_predicted).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93970803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.26 ms ± 793 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "svm.predict([X_pca_test[np.random.randint(0, 9999)]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a7fdf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf3 = (y_test != (rf3.predict(X_test))).sum()\n",
    "print(y_pred_rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7de89371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.3 ms ± 1.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rf3.predict([X_test[np.random.randint(0, 9999)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a4ff41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    }
   ],
   "source": [
    "y_pred_ovr_pca = (y_test != (ovr.predict(X_pca_test))).sum()\n",
    "print(y_pred_ovr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "934e7eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.81 ms ± 165 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ovr.predict([X_pca[np.random.randint(0, 9999)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0152f9",
   "metadata": {},
   "source": [
    "We decide to go with the Support Vector Machine trained on X_pca which was simply dimension-reduced by principal component\n",
    "analysis, based on cross-validation score of roughly 98%, precision and recall of about 0.98 each, based on the training time\n",
    "of 111s. Other classifiers with similar cross-validation scores, precision and recall had greater training time.\n",
    "\n",
    "Further, svm demonstrates the lowest failure rates of all the three models. It also seems to predict random samples slightly\n",
    "faster in roughly 6-7 ms (comparable to the ovr). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
